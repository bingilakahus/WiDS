{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "63cd166c-0952-49d6-bf57-667e3d7c9a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing all libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torchvision\n",
    "from scipy.io import loadmat\n",
    "from torchvision import transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from scipy.io import loadmat\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2ee10c56-4b0b-4500-89a2-2a749218a0ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the MNIST dataset\n",
    "mnist = loadmat(\"C:\\\\Users\\\\rohan\\\\OneDrive - Indian Institute of Technology Bombay\\\\IITB\\\\WiDS\\\\mnist-original.mat\")\n",
    "\n",
    "# Extract data and labels\n",
    "data = mnist['data']\n",
    "labels = mnist['label'][0]\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "data_tensor = torch.Tensor(data).T\n",
    "labels_tensor = torch.Tensor(labels)\n",
    "\n",
    "# Creating a reshaped tensor which has the same dimensions as that of the original image\n",
    "reshaped_data = data_tensor.view(70000, 28, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d9d2f599-f4dc-43d6-9091-5a9cf1e3ed4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting into training and testing data\n",
    "train_data , test_data = train_test_split(reshaped_data, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9669c763-5e70-4b74-89e0-1725d3abb24c",
   "metadata": {},
   "outputs": [],
   "source": [
    "numb_batch = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ffe99fde-90d2-4254-918b-08387b92d53b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to mnist_data\\MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting mnist_data\\MNIST\\raw\\train-images-idx3-ubyte.gz to mnist_data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to mnist_data\\MNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting mnist_data\\MNIST\\raw\\train-labels-idx1-ubyte.gz to mnist_data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to mnist_data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting mnist_data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz to mnist_data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to mnist_data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting mnist_data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz to mnist_data\\MNIST\\raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "T = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor()\n",
    "])\n",
    "train_data = torchvision.datasets.MNIST('mnist_data', train=True, download=True, transform=T)\n",
    "val_data = torchvision.datasets.MNIST('mnist_data', train=False, download=True, transform=T)\n",
    "\n",
    "train_dl = torch.utils.data.DataLoader(train_data, batch_size = numb_batch)\n",
    "val_dl = torch.utils.data.DataLoader(val_data, batch_size = numb_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "44437ce4-92e0-48e7-8406-e1d3399dec5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lenet():\n",
    "    model = nn.Sequential(\n",
    "        nn.Conv2d(1, 6, 5, padding=2),\n",
    "        nn.ReLU(),\n",
    "        nn.AvgPool2d(2, stride=2),\n",
    "        nn.Conv2d(6, 16, 5, padding=0),\n",
    "        nn.ReLU(),\n",
    "        nn.AvgPool2d(2, stride=2),\n",
    "        nn.Flatten(),\n",
    "        nn.Linear(400, 120),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(120, 84),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(84, 10)\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1fdceec6-099b-43f5-a94e-95bd13dbe4fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, data):\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    for i, (images, labels) in enumerate(data):\n",
    "        images = images.cuda()\n",
    "        x = model(images)\n",
    "        value, pred = torch.max(x,1)\n",
    "        pred = pred.data.cpu()\n",
    "        total += x.size(0)\n",
    "        correct += torch.sum(pred == labels)\n",
    "    return correct*100./total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4ec324e5-b5c5-4895-a854-7e3af17a5c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_dl, val_dl, numb_epoch=3, lr=1e-3):\n",
    "    accuracies = []\n",
    "    cec = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    max_accuracy = 0\n",
    "    for epoch in range(numb_epoch):\n",
    "        for i, (images, labels) in enumerate(train_dl):\n",
    "            optimizer.zero_grad()\n",
    "            pred = model(images)\n",
    "            loss = cec(pred, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        accuracy = float(validate(model, val_dl))\n",
    "        accuracies.append(accuracy)\n",
    "        if accuracy > max_accuracy:\n",
    "            best_model = copy.deepcopy(model)\n",
    "            max_accuracy = accuracy\n",
    "            print(\"Best Model Accuracy: \", accuracy)\n",
    "        print('Epoch:', epoch+1, \"Accuracy:\", accuracy, '%')\n",
    "    plt.plot(accuracies)\n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "276f41b5-ee97-4893-825c-616250098208",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c479fae5-c338-41a3-b7ad-f5ce4ad2d2a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be40111c-b3b2-4aa3-9c86-6561595cfbf7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e61ba252-9830-4bc7-a3eb-6561764b8399",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Test Accuracy: 0.1144\n",
      "Epoch [2/10], Test Accuracy: 0.1179\n",
      "Epoch [3/10], Test Accuracy: 0.1171\n",
      "Epoch [4/10], Test Accuracy: 0.1176\n",
      "Epoch [5/10], Test Accuracy: 0.1139\n",
      "Epoch [6/10], Test Accuracy: 0.1170\n",
      "Epoch [7/10], Test Accuracy: 0.1174\n",
      "Epoch [8/10], Test Accuracy: 0.1180\n",
      "Epoch [9/10], Test Accuracy: 0.1172\n",
      "Epoch [10/10], Test Accuracy: 0.1178\n",
      "Confusion Matrix:\n",
      "[[   0 1367    7    6    5    0   10   10    9    9]\n",
      " [   4 1570    9   12    4    0    8   17    5   16]\n",
      " [   3 1334    8    7    4    3    9   17   11   16]\n",
      " [   1 1362    6   19    0    0    2   18    9   16]\n",
      " [   3 1221    9   15    5    2    6   22    7    9]\n",
      " [   0 1222    3   15    6    0    1   22    8    7]\n",
      " [   3 1276    5   13    4    2    6   17    9    8]\n",
      " [   5 1359    9   12    3    1    5   25   14   14]\n",
      " [   1 1280    5    9    3    1    5   16    5   12]\n",
      " [   7 1299    7   17    5    3    4   16    8   11]]\n",
      "Overall Accuracy: 0.1178\n"
     ]
    }
   ],
   "source": [
    "# Convert the NumPy arrays to PyTorch tensors\n",
    "train_data_tensor = torch.Tensor(train_data)\n",
    "test_data_tensor = torch.Tensor(test_data)\n",
    "\n",
    "# Reshape the data to match the original image dimensions\n",
    "train_data_reshaped = train_data_tensor.view(-1, 1, 28, 28)\n",
    "test_data_reshaped = test_data_tensor.view(-1, 1, 28, 28)\n",
    "\n",
    "# Convert labels to integers\n",
    "labels_tensor = labels_tensor.long()\n",
    "\n",
    "# Splitting into training and testing labels\n",
    "train_labels, test_labels = train_test_split(labels_tensor.numpy(), test_size=0.2)\n",
    "train_labels_tensor = torch.Tensor(train_labels).long()\n",
    "test_labels_tensor = torch.Tensor(test_labels).long()\n",
    "\n",
    "# Define the CNN model\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.fc1 = nn.Linear(64 * 7 * 7, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool(x)\n",
    "        x = x.view(-1, 64 * 7 * 7)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Instantiate the model, define loss function and optimizer\n",
    "model = SimpleCNN()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Convert data and labels to PyTorch DataLoader\n",
    "train_dataset = TensorDataset(train_data_reshaped, train_labels_tensor)\n",
    "test_dataset = TensorDataset(test_data_reshaped, test_labels_tensor)\n",
    "\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Training the model\n",
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for batch_data, batch_labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_data)\n",
    "        loss = criterion(outputs, batch_labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Testing the model\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for batch_data, batch_labels in test_loader:\n",
    "            outputs = model(batch_data)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += batch_labels.size(0)\n",
    "            correct += (predicted == batch_labels).sum().item()\n",
    "\n",
    "        accuracy = correct / total\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Test Accuracy: {accuracy:.4f}')\n",
    "\n",
    "# Evaluate the final model on the entire test set\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_outputs = model(test_data_reshaped)\n",
    "    _, predicted_labels = torch.max(test_outputs, 1)\n",
    "\n",
    "# Calculate and print the confusion matrix\n",
    "conf_matrix = confusion_matrix(test_labels_tensor, predicted_labels)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# Calculate and print the overall accuracy\n",
    "accuracy = accuracy_score(test_labels_tensor, predicted_labels)\n",
    "print(f\"Overall Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Save the trained model\n",
    "torch.save(model.state_dict(), 'mnist_cnn_model.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f9272a72-801a-4400-af45-ab3259977f2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([627, 70000])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e52e0d57-14df-439a-b2c7-c0cb9c645548",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
